
# ğŸ§  Multi-Agent AI System with LangGraph, MCP & Groq

This project demonstrates a modular, multi-agent system using:

- **LangGraph** for agent orchestration  
- **Groq LLMs** via `.env`-based configuration  
- **Model Context Protocol (MCP)** for shared agent memory  
- **Python** with LangChain & OpenAI SDK (Groq-compatible)

> ğŸ’¡ Use this project as a starting point for building intelligent agent-based workflows or capacity planning tools.

---

## ğŸ” Overview

This system simulates a real-world AI task resolution flow using multiple autonomous agents:

1. `InputAgent` â€“ Captures and stores the user query
2. `PlannerAgent` â€“ Classifies the task type (e.g., "lookup")
3. `KnowledgeAgent` â€“ Uses an LLM (from Groq) to provide an answer
4. Context is shared via a local JSON-based **Model Context Protocol (MCP)**

Agents communicate through a LangGraph-powered directed graph, enabling **stateful, flexible routing**.

---

## ğŸ§± Tech Stack

| Component        | Tech/Tool                    |
|------------------|------------------------------|
| Agent Orchestration | `LangGraph`                  |
| LLM Provider     | `Groq` via OpenAI-compatible API |
| Context Storage  | JSON-based MCP (Model Context Protocol) |
| Agent Framework  | `LangChain`, `RunnableLambda` |
| Secrets Mgmt     | `.env` (via `python-dotenv`)  |

---

## ğŸ“ Project Structure

```
multi_agent_langgraph/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ input_agent.py
â”‚   â”œâ”€â”€ planner_agent.py
â”‚   â”œâ”€â”€ knowledge_agent.py
â”œâ”€â”€ mcp/
â”‚   â””â”€â”€ context_store.py
â”œâ”€â”€ main.py
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

1. **Clone the repo**

```bash
git clone https://github.com/your-org/multi-agent-groq.git
cd multi-agent-groq
```

2. **Install dependencies**

```bash
pip install -r requirements.txt
```

3. **Configure `.env` with Groq API**

```
OPENAI_API_KEY=your_groq_api_key
OPENAI_BASE_URL=https://api.groq.com/openai/v1
```

4. **Run the project**

```bash
python main.py
```

---

## ğŸ§  Example Usage

```
User: what is LLM?

[Final Output]
LLM is large language model...
```

---

## ğŸ’¡ Key Concepts

### ğŸ§¬ LangGraph
A stateful, directed graph framework for chaining AI agents with memory, branching, and retries.

### ğŸ§  MCP (Model Context Protocol)
A lightweight context manager that allows all agents to read/write to shared memory (`context.json`), ensuring persistence and traceability.

### ğŸ”— Agent-to-Agent (A2A) Protocol
Agents are decoupled but connected through shared state. LangGraph handles the orchestration and routing.

---

## ğŸš€ Future Enhancements

- Add **LangGraph branching** for more task types
- Add **RAG (Retrieval-Augmented Generation)** with internal docs
- Integrate **LangSmith** for tracing and debugging
- Replace MCP JSON with Redis for scalable state sharing
- Add **Streamlit UI** for internal demos

---

## ğŸ“„ License

This project is licensed under the **Apache 2.0 License**.  
Built for educational and prototyping purposes.

---

## ğŸ§‘â€ğŸ’» Author


